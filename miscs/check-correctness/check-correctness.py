#! /bin/python3

import numpy as np
from scipy.linalg import fractional_matrix_power
from scipy.special import softmax


#
# Initializations.
#

learning_rate = 0.1
num_vertices = 4039
layer_config = (602, 1000, 41)
file_dir = "../../../data/"

feat_file = file_dir + "features"
label_file = file_dir + "labels"
snap_file = file_dir + "fb.graph"
weights_file = "./weights-602-1000-41"

# Weights generated by the weightserver.
weights = [np.empty(shape=(layer_config[0], layer_config[1]), dtype=float),
           np.empty(shape=(layer_config[1], layer_config[2]), dtype=float),
           np.empty(shape=(layer_config[0], layer_config[1]), dtype=float),
           np.empty(shape=(layer_config[1], layer_config[2]), dtype=float)]
with open(weights_file, "r") as fweights:
    read_state, row_idx = -1, 0
    mat_cnt = -1
    for line in fweights.readlines():
        line = line.strip()
        if line == "Matrix Dims: (602, 1000)":
            mat_cnt += 1
            row_idx = 0
        elif line == "Matrix Dims: (1000, 41)":
            mat_cnt += 1
            row_idx = 0
        elif line[:2] == "U:":
            continue
        elif len(line) > 0:
            weights[mat_cnt][row_idx] = list(map(float, line.split()))
            row_idx += 1
# print(weights[0])
# print(weights[1])

# Read in initial features.
input_feats = np.empty(shape=[num_vertices, layer_config[0]], dtype=float)
with open(feat_file, "r") as ffeats:
    row_idx = 0
    for line in ffeats.readlines():
        line = line.strip()
        if len(line) > 0:
            input_feats[row_idx] = list(map(float, line.split(",")))
            row_idx += 1
# print(input_feats)

# Read in target lables one-hot representation.
target_labels = np.empty(shape=(num_vertices, layer_config[2]), dtype=float)
with open(label_file, "r") as flabels:
    row_idx = 0
    for line in flabels.readlines():
        line = line.strip()
        if len(line) > 0:
            one_hot = [1. if i == int(line) else 0 for i in range(layer_config[2])]
            target_labels[row_idx] = one_hot
            row_idx += 1
# print(target_labels)

# Read in the graph and construct adjancency and degree matrix.
adj_mat = np.identity(num_vertices)
deg_mat = np.identity(num_vertices)
with open(snap_file, "r") as fgraph:
    for line in fgraph.readlines():
        if len(line.strip()) > 0:
            vsrc, vdst = tuple([int(num) for num in line.strip().split()])
            assert(0 <= vsrc < num_vertices and 0 <= vdst < num_vertices)
            adj_mat[vdst, vsrc] = 1
            deg_mat[vdst, vdst] += 1


#
# Functions used in the epoch.
#

normed_deg_mat = fractional_matrix_power(deg_mat, -0.5)
S_mat = np.dot(normed_deg_mat, np.dot(adj_mat, normed_deg_mat))

def activate(mat):
    return np.tanh(mat)

def activate_derivate(mat):
    return 1 - np.multiply(np.tanh(mat), np.tanh(mat))

def softmax_row(mat):
    return softmax(mat, axis=1)


#
# Calculation.
#

# Forward.
act_mat0 = input_feats
z_mat1 = np.dot(S_mat, np.dot(act_mat0, weights[0]))
act_mat1 = activate(z_mat1)
z_mat2 = np.dot(S_mat, np.dot(act_mat1, weights[1]))
act_mat2 = activate(z_mat2)

print("Activation (1): ")
print(act_mat1)
print("Activation (2): ")
print(act_mat2)

# Backward.
gd_mat2 = np.multiply(softmax_row(act_mat2) - target_labels, activate_derivate(z_mat2))
gd_mat1 = np.multiply(np.matmul(gd_mat2, weights[1].transpose()), activate_derivate(z_mat1))
weight_updates1 = learning_rate * np.matmul(act_mat0.transpose(), gd_mat1)
weight_updates2 = learning_rate * np.matmul(act_mat1.transpose(), gd_mat2)
weights[0] -= weight_updates1
weights[1] -= weight_updates2

print("W (1): ")
print(weights[0])
print("W (2): ")
print(weights[1])

print("Abs sum of 1st layer:")
print(np.sum(np.abs(weights[0] - weights[2])))
print("Abs sum of 2nd layer:")
print(np.sum(np.abs(weights[1] - weights[3])))